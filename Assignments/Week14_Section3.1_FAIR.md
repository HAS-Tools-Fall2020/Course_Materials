# Week 14: FAIR Science
This week we are going to explore what it takes to make work Findable, Accessible, Interoperable and Reusable (FAIR).
___
## Table of Contents:
1. [ To Do List](#todo)
1. [ Resources](#resources)
1. [ Assignment](#assignment)
___
<a name="todo"></a>
## To Do List
1. Find a paper with an associated repo and review it

2. Complete your forecast by whatever means you would like.

2. Submit the following **2 things** by **noon on Monday**:
 - Your forecast to the forecast Precipitation
 - A md file submission for HW14 in the `submission` folder of your repo.

___
<a name="references"></a>
## References and resources
- [Intro to Earth Data Science Chapter 8 Lesson 3](https://www.earthdatascience.org/courses/use-data-open-source-python/earth-data-science-workflows/design-efficient-automated-data-workflows/efficient-workflow-best-practices/):  Data Workflow Best Practices - Things to Consider When Processing Data
- [Cyverse FAIR Data Training Resources](https://learning.cyverse.org/projects/foss-2020/en/latest/Data_management/FAIR.html)
- [Advancing FAIR Data in Earth, Space, and Environmental Science](https://eos.org/agu-news/advancing-fair-data-in-earth-space-and-environmental-science)
- [Natures's FAIR data policy](https://www.nature.com/articles/d41586-019-00075-3)

___
<a name="assignment"></a>
## Assignment 14: In Search of FAIR Research
This week there is NO coding assignment.  However, there is still a written assignment and you should submit your forecast to the competition as usual.

#### Assignment
Your assignment this week is to go in search of a research project which has an associated repo and see if you are able to reproduce their results. For for reference, I am expecting you to spend **no more than 2.5 hours on this**. It is not your assignment to fully reproduce their research, it is your assignment to **try** and to reflect on that experience whether it is successful or not.

**Part 1: Find a suitable repo to explore**
I would recommend you find a journal article to start from but you are also welcome to go to any project or research website. The requirement is that you find a set of results or a product which includes the code and data associated with generating those results.  Below is a list of a few journals that have good requirements for publishing code and might be a good place to start. Please don't feel limited by this list though, you can start anywhere.

  - [Nature Climate change](https://www.nature.com/nclimate/)
  - [Nature Communicatitons](https://www.nature.com/ncomms/)
  - [Geoscientific Model Development](https://gmd.copernicus.org/articles/13/5053/2020/)
  - [Scientific Data](https://www.nature.com/sdata/)

When looking for a paper, don't spend time reading the paper (although you probably want to stick to papers where the title is at least somewhat relevant to you) first go to the bottom where they have code and data availability statements and see if there is a repo or other website with code associated with the paper. **You must pick a paper that has python codes somehow included with it**. In other words: don't pick a paper that has no codes associated with it or codes not written in Python and then write an evaluation saying that there were no codes.  

**Part 2: Clone the repo and try to run their scripts**
Spend no more than **1 hour** trying to run the scripts associated with this paper. Don't spend your time trying to figure out all of the math behind their functions and how they work. Your goal is to see if you can (1) understand their readme and get the code to run (2) generally understand/follow what is in the repo and how it works (3)recreate any figures from the paper.

**Part 3: Reflect on your experience**
In your homework submissions folder create a file `LastName_HW14.md` and answer the following questions:
1. What is the paper or project you picked? Include a title, a link the the paper and a 1-2 sentence summary of what its about.

2. What codes and/or data are associated with this paper? Provide any link to the codes and datasets and a 1-2 sentence summary of what was included with the paper (i.e. was it a github repo? A python package?A database? Where was it stored and how?)

3. Summarize your experience trying to understand the repo: Was their readme helpful? How was their organization? What about documentation within the code itself?

4. Summarize your experience trying to work with their repo: What happened? Where  you successful? Why or why not?

5. Summarize your experience working with the data associated with this research. Could you access the data? Where was it? Did it have a DOI? What format was it in?

5. Did this experience teach you anything about your own repo or projects? Things you might start or stop doing?


#### Forecast Rules for this week:
- You can do any mathematical operation using numpy or pandas package to do so and you can use LinearRegression models from the sklearn package.  

- You can use and of the datasets we have used so far in your analysis

- You can use the streamflow data up to the Saturday before the forecast is due for making your decisions.

#### Submission Instructions
1.  Submit your forecast to the forecast competition following normal procedures.
2. Submit your ReadMe file to your submissions folder `LastName_HW14.md`
